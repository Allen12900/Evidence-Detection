{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7YL8MVJm88I"
      },
      "source": [
        "# Logistic Regression & SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6t6c_fCynDYB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xd4DtG-PnF7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdca798-5345-4d8e-e63a-07e4c104c987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "0    4286\n",
            "1    1640\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "0    15654\n",
            "1     5854\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load training and validation datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "dev_df = pd.read_csv(\"dev.csv\")\n",
        "\n",
        "label_counts = train_df['label'].value_counts()\n",
        "val_label_counts = dev_df['label'].value_counts()\n",
        "print(val_label_counts)\n",
        "print(label_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUT_mbTGoERY"
      },
      "outputs": [],
      "source": [
        "# Combine claim and evidence into a single text feature\n",
        "train_df[\"text\"] = train_df[\"Claim\"] + \" \" + train_df[\"Evidence\"]\n",
        "dev_df[\"text\"] = dev_df[\"Claim\"] + \" \" + dev_df[\"Evidence\"]\n",
        "\n",
        "# Extract labels\n",
        "y_train = train_df[\"label\"]\n",
        "y_dev = dev_df[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0JVhTDboFTa"
      },
      "outputs": [],
      "source": [
        "# Convert text into TF-IDF features\n",
        "tfidf = TfidfVectorizer(max_features=18000, ngram_range=(1,4))  # Unigrams & bigrams & trigrams\n",
        "X_train_tfidf = tfidf.fit_transform(train_df[\"text\"])\n",
        "X_dev_tfidf = tfidf.transform(dev_df[\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SMOTE"
      ],
      "metadata": {
        "id": "83gkzvBmoka-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled_smote, y_train_resampled_smote = smote.fit_resample(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "id": "ZQziP6XNos__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Logistic Regression with SMOTE ---\")\n",
        "# Creating the class weights\n",
        "pos = np.sum(y_train_resampled_smote == 1)\n",
        "neg = np.sum(y_train_resampled_smote == 0)\n",
        "\n",
        "variation = 0.09 # This is used to vary the bias\n",
        "class_weights = {0: pos/(neg+pos) + variation, 1: neg/(pos+neg) - variation}\n",
        "\n",
        "# Logistic Regression model with SMOTE\n",
        "logreg_smote = LogisticRegression(max_iter=500, tol=0.00005, class_weight=class_weights, C=1.18, random_state=42)\n",
        "\n",
        "# Fit the model on training and dev sample.\n",
        "logreg_smote.fit(X_train_resampled_smote, y_train_resampled_smote)\n",
        "y_pred_logreg_smote = logreg_smote.predict(X_dev_tfidf)\n",
        "\n",
        "# Calculating metrics\n",
        "f1_logreg_smote = f1_score(y_dev, y_pred_logreg_smote)\n",
        "accuracy_logreg_smote = accuracy_score(y_dev, y_pred_logreg_smote)\n",
        "macrof1_logreg_smote = f1_score(y_dev, y_pred_logreg_smote, average='weighted')\n",
        "\n",
        "# Printing metrics and report\n",
        "print(f\"Validation F1-Score (SMOTE): {f1_logreg_smote}\")\n",
        "print(f\"Validation Accuracy (SMOTE): {accuracy_logreg_smote}\")\n",
        "print(f\"Validation Macro F1-Score (SMOTE): {macrof1_logreg_smote}\")\n",
        "print(classification_report(y_dev, y_pred_logreg_smote))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H_PNtCvp4iQ",
        "outputId": "37e0179d-b3a9-49ab-ee16-b4ca9a35f386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Logistic Regression with SMOTE ---\n",
            "{0: np.float64(0.59), 1: np.float64(0.41000000000000003)}\n",
            "Validation F1-Score (SMOTE): 0.6425970873786407\n",
            "Validation Accuracy (SMOTE): 0.8012149848126898\n",
            "Validation Macro F1-Score (SMOTE): 0.8015116054717532\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86      4286\n",
            "           1       0.64      0.65      0.64      1640\n",
            "\n",
            "    accuracy                           0.80      5926\n",
            "   macro avg       0.75      0.75      0.75      5926\n",
            "weighted avg       0.80      0.80      0.80      5926\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM"
      ],
      "metadata": {
        "id": "QRPuUHqcqT2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"\\n--- SVM with SMOTE ---\")\n",
        "# svm_smote = SVC(kernel=\"linear\", C=1.0, class_weight=None)\n",
        "# svm_smote.fit(X_train_resampled_smote, y_train_resampled_smote)\n",
        "# y_pred_svm_smote = svm_smote.predict(X_dev_tfidf)\n",
        "# f1_svm_smote = f1_score(y_dev, y_pred_svm_smote)\n",
        "# print(f\"Validation F1-Score (SMOTE): {f1_svm_smote}\")\n",
        "# print(classification_report(y_dev, y_pred_svm_smote))"
      ],
      "metadata": {
        "id": "RkVXcZTkaAie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Original Logistic Regression and SVM\n"
      ],
      "metadata": {
        "id": "Q_dFY5Fdqobv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPXEm5rCoKMn"
      },
      "outputs": [],
      "source": [
        "# # Train Logistic Regression model\n",
        "# pos = 5854\n",
        "# neg = 15654\n",
        "# variation = 0.09\n",
        "# class_weights = {0: pos/(neg+pos) + variation, 1: neg/(pos+neg) - variation}\n",
        "\n",
        "# logreg = LogisticRegression(max_iter=500, class_weight=class_weights, C=1.17)\n",
        "# logreg.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# # Predict on validation set\n",
        "# y_pred_logreg = logreg.predict(X_dev_tfidf)\n",
        "\n",
        "# # Evaluate performance\n",
        "# print(\"Logistic Regression Performance:\")\n",
        "# f1 = f1_score(y_dev, y_pred_logreg)\n",
        "# accuracy = accuracy_score(y_dev, y_pred_logreg)\n",
        "# macrof1 = f1_score(y_dev, y_pred_logreg, average='weighted')\n",
        "# print(f\"Validation F1-Score: {f1}\")\n",
        "# print(f\"Validation Accuracy: {accuracy}\")\n",
        "# print(f\"Validation Macro F1-Score: {macrof1}\")\n",
        "# print(classification_report(y_dev, y_pred_logreg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5iuy6iJobK0"
      },
      "outputs": [],
      "source": [
        "# # Train SVM model\n",
        "# svm = SVC(kernel=\"linear\", C=1.0, class_weight='balanced')  # Linear kernel is best for text classification\n",
        "# svm.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# # Predict on validation set\n",
        "# y_pred_svm = svm.predict(X_dev_tfidf)\n",
        "\n",
        "# # Evaluate performance\n",
        "# print(\"SVM Performance:\")\n",
        "# f1 = f1_score(y_dev, y_pred_svm)\n",
        "# print(f\"Accuracy: {f1}\")\n",
        "# print(classification_report(y_dev, y_pred_svm))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gridsearch"
      ],
      "metadata": {
        "id": "C9_1-62hprTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Example for Logistic Regression\n",
        "param_grid = {'C': [1.17, 1.16]}\n",
        "grid_logreg = GridSearchCV(LogisticRegression(max_iter=500, class_weight='balanced'),\n",
        "                           param_grid, cv=5, scoring='f1_weighted')\n",
        "grid_logreg.fit(X_train_tfidf, y_train)\n",
        "print(\"Best parameters for Logistic Regression:\", grid_logreg.best_params_)\n"
      ],
      "metadata": {
        "id": "cTKYzlzK5vC3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}